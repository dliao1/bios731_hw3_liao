---
title: 'Homework 3'
header-includes:
  - \usepackage{multirow}
output:
  pdf_document: default
urlcolor: blue
---

```{r, include=FALSE}

library(tidyverse)
library(here)
library(tidyr)
library(knitr)
library(dplyr)
library(ggplot2)
library(dplyr)
library(cowplot)
library(kableExtra)
library(patchwork)


knitr::opts_chunk$set(tidy = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(echo = FALSE)
```

## Context

This assignment reinforces ideas in Module 3: Cluster computing.


## Due date and submission

Please submit (via Canvas) a PDF containing a link to the web address of the GitHub repo containing your work for this assignment; git commits after the due date will cause the assignment to be considered late. 



## Points

```{r, echo = FALSE}
tibble(
  Problem = c("Problem 0", "Problem 1"),
  Points = c(20, 80)
) %>%
  knitr::kable()
```


## Problem 0 

This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.

To that end:

* Create a public GitHub repo + local R Project
* Submit your whole project folder to GitHub 
* Submit a PDF knitted from Rmd to Canvas. Your solutions to the problems here should be implemented in your .Rmd file, and your git commit history should reflect the process you used to solve these Problems.


## Problem 1

Continuation of Homework 1. Here, we will re-run part of the simulation study from Homework 1 with some minor changes, on the cluster. Cluster computing space is limited so we will not run too many jobs or simulations.  

### Problem 1 setup

The simulation study is specified below:

Below is a multiple linear regression model, where we are interested in primarily treatment effect.


$$Y_i = \beta_0 + \beta_{treatment}X_{i1} + \mathbf{Z_i}^T\boldsymbol{\gamma} + \epsilon_i$$


Notation is defined below: 

* $Y_i$: continuous outcome
* $X_{i1}$: treatment group indicator; $X_{i1}=1$ for treated 
* $\mathbf{Z_i}$: vector of potential confounders
* $\beta_{treatment}$: average treatment effect, adjusting for $\mathbf{Z_i}$
* $\boldsymbol{\gamma}$: vector of regression coefficient values for confounders 
* $\epsilon_i$: errors, we will vary how these are defined


In our simulation, we want to 

* Estimate $\beta_{treatment}$
  * Evaluate $\beta_{treatment}$ through bias, coverage, type 1 error, and power
  * We will use 2 methods to compute $se(\hat{\beta}_{treatment})$ and coverage:
    1. Wald confidence intervals (the standard approach)
    2. Nonparametric bootstrap percentile intervals
  * Evaluate computation times for each method to compute a confidence interval

* Evaluate these properties at:
  - Sample size $n =\{20\}$
  - True values $\beta_{treatment} \in \{0, 0.5\}$
  - True $\epsilon_i$ normally distributed with $\epsilon_i \sim N(0, 2)$
  - True $\epsilon_i$ coming from a highly right skewed distribution
    - Generate data from a Gamma distribution with `shape = 1` and `rate = 2`.

* Assume that there are no confounders ($\boldsymbol{\gamma} = 0$)
* Use a full factorial design
* Use same `nsim` as previous assignment.


### Problem 1 tasks

We will execute this full simulation study. For full credit, make sure to implement the following:

**Workflow:**
* Use structured scripts and subfolders following guidance from the cluster computing project organization lecture
* Instead of parallelizing your simulation scenarios (as in HW1), each simulation scenario should be assigned a different JOBID on the cluster.


**Presenting results:**

Create plots with *Monte Carlo standard error bars* to summarize the following:

- Bias of $\hat{\beta}$
- Coverage of $\hat{\beta}$
- Power
- Type 1 error

Write 1-2 paragraphs summarizing these results.

```{r}
num_scenarios <- 1 * 2 * 2

mc_err <- 0.01
cover <- 0.95
alpha <- 1 - 0.95
n_sim <- (cover * (1 - cover))/mc_err^2
n_sim
```

```{r}
all_wald_results <- vector("list", num_scenarios)
all_boot_p_results <- vector("list", num_scenarios)

# Loop through each scenario file
for (i in 1:num_scenarios) {
  file_path <- here("results", "sim_wald", paste0("scenario_", i, ".RDA"))
  load(file_path)
  
  all_wald_results[[i]] <- all_wald_estim %>% 
    mutate(err_type = ifelse(err_type == 0, "Gamma", "Normal"))
  
  file_path <- here("results", "sim_boot_percentile", paste0("scenario_", i, ".RDA"))
  load(file_path)
  
  all_boot_p_results[[i]] <- all_boot_percent_estim %>%
    mutate(err_type = ifelse(err_type == 0, "Gamma", "Normal"))
}

```

```{r}
# Each list is of length 4 since 4 parameter combinations
all_biases <- rep(NA, num_scenarios)
var_hat <- rep(NA, num_scenarios)
wald_coverage <- rep(NA, num_scenarios)
boot_p_coverage <- rep(NA, num_scenarios)
wald_time <- rep(NA, num_scenarios)
boot_p_time <- rep(NA, num_scenarios)
all_n <- rep(NA, num_scenarios)
all_beta_true <- rep(NA, num_scenarios)
all_err_type <- rep(NA, num_scenarios)
scenario_num <- rep(NA, num_scenarios)
mean_wald_se_beta <- rep(NA, num_scenarios)
mean_boot_p_se_beta <- rep(NA, num_scenarios)
se_hat <- rep(NA, num_scenarios)
se_hat_se <- rep(NA, num_scenarios)
wald_type1 <- rep(NA, num_scenarios)
boot_p_type1 <- rep(NA, num_scenarios)
wald_power <- rep(NA, num_scenarios)
boot_p_power <- rep(NA, num_scenarios)

bias_mcse <- rep(NA, num_scenarios)
coverage_mcse <- rep(NA, num_scenarios)
wald_power_mcse <- rep(NA, num_scenarios)
wald_type1_mcse <- rep(NA, num_scenarios)

n_sim <- 475

for (i in 1:num_scenarios) {
  
  all_biases[i] <- (1/n_sim) * sum(all_wald_results[[i]]$beta_hat - all_wald_results[[i]]$beta_true)
  var_hat[i] <- sd(all_wald_results[[i]]$beta_hat)
  se_hat[i] <- mean(all_wald_results[[i]]$se_beta)
  se_hat_se[i] <- sd(all_wald_results[[i]]$se_beta)
  wald_coverage[i] <- mean(all_wald_results[[i]]$coverage == 1) 
  boot_p_coverage[i] <- mean(all_boot_p_results[[i]]$coverage == 1) 
  wald_time[i] <- mean(all_wald_results[[i]]$time)
  boot_p_time[i] <- mean(all_boot_p_results[[i]]$time)
  all_n[i] <- unique(all_wald_results[[i]]$n)[[1]]
  all_beta_true[i] <- unique(all_wald_results[[i]]$beta_true)
  all_err_type[i] <- unique(all_wald_results[[i]]$err_type)
  mean_wald_se_beta[i] <- mean(all_wald_results[[i]]$se_beta)
  mean_boot_p_se_beta[i] <- mean(all_boot_p_results[[i]]$se_beta)
  
  # Power = p(detecting an effect)
  # = p(rejecting null when null false)
  # = 1 - p(NOT rejecting null when null false)
  # = 1 - p(0 in CI when beta_true = 0.5)
  #  = p(0 not in CI when beta_true = 0.5)
  
  # type I error
  # p(rejecting null when null is true)
  # = p(0 not in CI when beta_true = 0)

  if (unique(all_wald_results[[i]]$beta_true)[[1]] == 0) {
    # Compute Type I Error when true beta is 0
    wald_type1[i] <- mean(all_wald_results[[i]]$ci_l > 0 | all_wald_results[[i]]$ci_u < 0)
    boot_p_type1[i] <- mean(all_boot_p_results[[i]]$ci_l > 0 | all_boot_p_results[[i]]$ci_u < 0)

    
  } else { # beta = 0.5
    # Compute Power when true beta is NOT 0
    wald_power[i] <- mean(all_wald_results[[i]]$ci_l > 0 | all_wald_results[[i]]$ci_u < 0)
    boot_p_power[i] <- mean(all_boot_p_results[[i]]$ci_l > 0 | all_boot_p_results[[i]]$ci_u < 0)

  }
  
  scenario_num[i] <- i
  
  bias_mcse[i] <- sqrt(sum((all_wald_results[[i]]$beta_hat - mean(all_wald_results[[i]]$beta_hat))^2) / (n_sim * (n_sim - 1)))

}


# this is 4 rows, 1 for each parameter combo
df <- bind_cols(
  scenario_num = scenario_num, 
  n = all_n, 
  beta_true = all_beta_true, 
  error_type = all_err_type, 
  bias = all_biases,
  bias_mcse = bias_mcse,
  var = var_hat,
  se_hat = se_hat,
  se_hat_se = se_hat_se,
  wald_coverage = wald_coverage,
  wald_coverage_mcse = sqrt(wald_coverage * (1-wald_coverage)/ n_sim) ,
  wald_time = wald_time,
  wald_power = wald_power,
  wald_power_mcse = sqrt(wald_power * (1-wald_power)/n_sim), 
  wald_type1 = wald_type1,
  wald_type1_mcse = sqrt(wald_type1 * (1-wald_type1)/n_sim),

  wald_se = mean_wald_se_beta,
  boot_p_coverage = boot_p_coverage,
  boot_p_coverage_mcse = sqrt(boot_p_coverage * (1-boot_p_coverage)/ n_sim) ,

  boot_p_time = boot_p_time,
  boot_p_se = mean_boot_p_se_beta,
  boot_p_power = boot_p_power,
  boot_p_power_mcse= sqrt(boot_p_power * (1-boot_p_power)/n_sim),

  boot_p_type1 = boot_p_type1,
  boot_p_type1_mcse = sqrt(boot_p_type1 * (1-boot_p_type1)/n_sim),

  
  )




```

#### Bias
```{r}
bias_table <- df %>%
  select(n, beta_true, error_type, bias) %>%  
  arrange(n, beta_true) %>%
  rename("N" = n, "True Beta" = beta_true) %>%
  pivot_wider(
    names_from = error_type,
    values_from = bias,   
  )

kable(bias_table, digits = 3, caption = "Bias Summary Table")
```

```{r}
ggplot(df, aes(x = error_type, y = bias, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  # Plot points for bias
  geom_errorbar(aes(ymin = bias - bias_mcse, ymax = bias + bias_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  # Error bars
  labs(title = "Bar plot of Bias",
       x = "Error Type",
       y = "Bias",
       color = "True Beta") +
  theme_minimal()
```




```{r}
coverage_table <- df %>%
  select(n, beta_true, error_type, wald_coverage, boot_p_coverage) %>%
  arrange(n, beta_true, error_type) %>%
  pivot_wider(
    names_from = error_type,  
    values_from = c(wald_coverage, boot_p_coverage),
    names_glue = "{error_type} {.value}", 
  ) %>%
  select(n, beta_true, starts_with("Gamma"), starts_with("Normal")) %>%
  rename(
    "N" = n,
    "True Beta" = beta_true,
    "Gamma Wald CI" = "Gamma wald_coverage",
    "Gamma Bootstrap Percentile CI" = "Gamma boot_p_coverage",
    "Normal Wald CI" = "Normal wald_coverage",
    "Normal Bootstrap Percentile CI" = "Normal boot_p_coverage",
  )


kable(coverage_table, digits = 3, caption = "Coverage Summary Table") %>%
  add_header_above(c(" " = 2, "Gamma" = 2, "Normal" = 2)) %>%
  column_spec(1, width = "1cm") %>%
  column_spec(2, width = "1cm") %>%
  column_spec(3:6, width = "2cm") 

```

#### Coverage

```{r}
y_min <- min(df$wald_coverage - df$wald_coverage_mcse, df$boot_p_coverage - df$boot_p_coverage_mcse)
y_max <- max(df$wald_coverage + df$wald_coverage_mcse, df$boot_p_coverage + df$boot_p_coverage_mcse)

wald_plot <- ggplot(df, aes(x = error_type, y = wald_coverage, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = wald_coverage - wald_coverage_mcse, 
                    ymax = wald_coverage + wald_coverage_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Wald Coverage", x = "Error Type", y = "Coverage (%)", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

boot_plot <- ggplot(df, aes(x = error_type, y = boot_p_coverage, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = boot_p_coverage - boot_p_coverage_mcse, 
                    ymax = boot_p_coverage + boot_p_coverage_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Bootstrap Percentile Coverage", x = "Error Type", y = "Coverage (%)", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

(wald_plot + boot_plot) + plot_layout(ncol = 2, heights = c(5))


```


#### Power


```{r}
y_min <- min(c(df$wald_power - df$wald_power_mcse, df$boot_p_power - df$boot_p_power_mcse), na.rm = TRUE)
y_max <- max(c(df$wald_power + df$wald_power_mcse, df$boot_p_power + df$boot_p_power_mcse), na.rm = TRUE)

wald_plot <- ggplot(df, aes(x = error_type, y = wald_power, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = wald_power - wald_power_mcse, 
                    ymax = wald_power + wald_power_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Wald Power", x = "Error Type", y = "Power", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

boot_plot <- ggplot(df, aes(x = error_type, y = boot_p_power, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = boot_p_power - boot_p_power_mcse, 
                    ymax = boot_p_power + boot_p_power_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Bootstrap Percentile Power", x = "Error Type", y = "Power", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

(wald_plot + boot_plot) + plot_layout(ncol = 2, heights = c(5))
```

#### Type 1 Error
```{r}
y_min <- min(c(df$wald_type1 - df$wald_type1_mcse, df$boot_p_type1 - df$boot_p_type1_mcse), na.rm = TRUE)
y_max <- max(c(df$wald_type1 + df$wald_type1_mcse, df$boot_p_type1 + df$boot_p_type1_mcse), na.rm = TRUE)

wald_plot <- ggplot(df, aes(x = error_type, y = wald_type1, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = wald_type1 - wald_type1_mcse, 
                    ymax = wald_type1 + wald_type1_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Wald Type I Error", x = "Error Type", y = "Type I Error", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

boot_plot <- ggplot(df, aes(x = error_type, y = boot_p_type1, color = as.factor(beta_true))) +
  geom_point(position = position_dodge(width = 0.3), size = 3) +  
  geom_errorbar(aes(ymin = boot_p_type1 - boot_p_type1_mcse, 
                    ymax = boot_p_type1 + boot_p_type1_mcse), 
                position = position_dodge(width = 0.3), width = 0.2) +  
  labs(title = "Bootstrap Percentile Type I Error", x = "Error Type", y = "Type I Error", color = "True Beta") +
  coord_cartesian(ylim = c(y_min, y_max)) +  
  theme_minimal()

(wald_plot + boot_plot) + plot_layout(ncol = 2, heights = c(5))
```







